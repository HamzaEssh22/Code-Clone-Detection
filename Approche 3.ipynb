{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAhXn0Y4PfSd",
        "outputId": "5d748fd3-d75f-489c-911b-0861e6bb9f9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv(\"/content/drive/MyDrive/CodeClones/train.csv\")\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/CodeClones/test.csv\")\n",
        "valid = pd.read_csv(\"/content/drive/MyDrive/CodeClones/valid.csv\")\n"
      ],
      "metadata": {
        "id": "11YhzwPSPkVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def preprocess_java_code(code):\n",
        "    # 1. Remove single-line and multi-line comments\n",
        "    code = re.sub(r'//.*?\\n|/\\*.*?\\*/', '', code, flags=re.S)\n",
        "\n",
        "    # 2. Remove string literals\n",
        "    code = re.sub(r'\"(?:\\\\.|[^\"\\\\])*\"|\\'(?:\\\\.|[^\\'\\\\])*\\'', 'STRING_LITERAL', code)\n",
        "\n",
        "    # 3. Remove numeric literals\n",
        "    code = re.sub(r'\\b\\d+(\\.\\d+)?\\b', 'NUMERIC_LITERAL', code)\n",
        "\n",
        "    # 4. Normalize case\n",
        "    code = code.lower()\n",
        "\n",
        "    # 5. Tokenize the code\n",
        "    tokens = re.findall(r'\\w+|[^\\w\\s]', code)\n",
        "\n",
        "    # 6. Remove unnecessary whitespace\n",
        "    processed_code = ' '.join(tokens)\n",
        "\n",
        "    return processed_code"
      ],
      "metadata": {
        "id": "NXSCAs_FPkd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['function1'] = train['func_x'].apply(preprocess_java_code)\n",
        "train['function2'] = train['func_y'].apply(preprocess_java_code)\n",
        "\n",
        "test['function1'] = test['func_x'].apply(preprocess_java_code)\n",
        "test['function2'] = test['func_y'].apply(preprocess_java_code)\n",
        "\n",
        "valid['function1'] = valid['func_x'].apply(preprocess_java_code)\n",
        "valid['function2'] = valid['func_y'].apply(preprocess_java_code)"
      ],
      "metadata": {
        "id": "eVveZWtZPt1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBpy_TAnPxIR",
        "outputId": "75ed2f9e-0964-4df2-f5b4-6f0d7fbf5425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import RobertaTokenizer\n",
        "\n",
        "class CodeCloneDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.tokenizer = RobertaTokenizer.from_pretrained('microsoft/codebert-base')\n",
        "        self.dataframe = dataframe\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        function1 = self.dataframe.iloc[idx]['function1']\n",
        "        function2 = self.dataframe.iloc[idx]['function2']\n",
        "        label = self.dataframe.iloc[idx]['Label']\n",
        "\n",
        "        encoded1 = self.tokenizer.encode_plus(\n",
        "            function1,\n",
        "            max_length=512,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "\n",
        "        encoded2 = self.tokenizer.encode_plus(\n",
        "            function2,\n",
        "            max_length=512,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids1': encoded1['input_ids'].squeeze(),\n",
        "            'input_ids2': encoded2['input_ids'].squeeze(),\n",
        "            'label': torch.tensor(label, dtype=torch.float32)\n",
        "        }\n"
      ],
      "metadata": {
        "id": "X0axqzvQPyGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# assuming `df` is your DataFrame\n",
        "train_dataset = CodeCloneDataset(train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "valid_dataset = CodeCloneDataset(valid)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "test_dataset = CodeCloneDataset(test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True)\n"
      ],
      "metadata": {
        "id": "ngaCfFYUgTBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from transformers import RobertaModel, RobertaTokenizer, AdamW\n",
        "\n",
        "class SiameseCodeBERT(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super(SiameseCodeBERT, self).__init__()\n",
        "        self.codebert = RobertaModel.from_pretrained(model_name)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        outputs = self.codebert(input_ids=input_ids)\n",
        "        return outputs.pooler_output  # return the [CLS] embedding\n"
      ],
      "metadata": {
        "id": "RWOKx-7hgrTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an instance of the model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = SiameseCodeBERT('microsoft/codebert-base').to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25kq7ZeDhMJz",
        "outputId": "549fc3eb-eac6-42fb-8ac9-2312a2528ca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "def compute_loss(out1, out2, labels, margin=1.0):\n",
        "    # Calculate Euclidean distance\n",
        "    euclidean_distance = torch.nn.functional.pairwise_distance(out1, out2)\n",
        "    # Contrastive Loss\n",
        "    loss_contrastive = torch.mean((1-labels) * torch.pow(euclidean_distance, 2) +\n",
        "                                  (labels) * torch.pow(torch.clamp(margin - euclidean_distance, min=0.0), 2))\n",
        "    return loss_contrastive\n",
        "\n",
        "# def compute_loss(out1, out2, labels):\n",
        "#     # Calculate Euclidean distance\n",
        "#     euclidean_distance = torch.nn.functional.pairwise_distance(out1, out2)\n",
        "#     # Contrastive Loss\n",
        "#     loss_contrastive = torch.mean((1-labels) * torch.pow(euclidean_distance, 2) +\n",
        "#                                   (labels) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "#     return loss_contrastive\n"
      ],
      "metadata": {
        "id": "thQntg2ahTBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "from tqdm import *\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Starting epoch {epoch+1}/{num_epochs}')\n",
        "\n",
        "    # Train\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for step, batch in enumerate(tqdm(train_loader, f\"Training :Epoch {epoch+1}/{num_epochs}\")):\n",
        "        optimizer.zero_grad()\n",
        "        input_ids1 = batch['input_ids1'].to(device)\n",
        "        input_ids2 = batch['input_ids2'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "        out1 = model(input_ids1)\n",
        "        out2 = model(input_ids2)\n",
        "        loss = compute_loss(out1, out2, labels)\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f'training loss: {total_loss/len(train_loader)}')\n",
        "\n",
        "    # Evaluate\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in valid_loader:\n",
        "            input_ids1 = batch['input_ids1'].to(device)\n",
        "            input_ids2 = batch['input_ids2'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "            out1 = model(input_ids1)\n",
        "            out2 = model(input_ids2)\n",
        "            loss = compute_loss(out1, out2, labels)\n",
        "            total_loss += loss.item()\n",
        "    print(f'Validation loss: {total_loss/len(valid_loader)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0Y_opOXhXP6",
        "outputId": "ac855ddc-62c7-4121-d3b8-942ac5937694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training :Epoch 1/3: 100%|██████████| 2094/2094 [26:54<00:00,  1.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 0.8819970927223616\n",
            "Validation loss: 0.11233298957996\n",
            "Starting epoch 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training :Epoch 2/3: 100%|██████████| 2094/2094 [27:15<00:00,  1.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 0.2575129350076261\n",
            "Validation loss: 0.11295038982598128\n",
            "Starting epoch 3/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training :Epoch 3/3: 100%|██████████| 2094/2094 [27:15<00:00,  1.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 0.2544745570466762\n",
            "Validation loss: 0.10914368355839417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have a DataLoader for your test set, named `test_dataloader`\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "model.eval()\n",
        "all_labels = []\n",
        "all_predictions = []\n",
        "correct_predictions = 0\n",
        "total_loss = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids1 = batch['input_ids1'].to(device)\n",
        "\n",
        "        input_ids2 = batch['input_ids2'].to(device)\n",
        "\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        out1 = model(input_ids1)\n",
        "        out2 = model(input_ids2)\n",
        "\n",
        "        loss = compute_loss(out1, out2, labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Computing predictions\n",
        "        euclidean_distance = torch.nn.functional.pairwise_distance(out1, out2)\n",
        "        predictions = (euclidean_distance > 0.4).float()\n",
        "        all_labels.extend(labels.detach().cpu().numpy())\n",
        "        all_predictions.extend(predictions.detach().cpu().numpy())\n",
        "\n",
        "avg_loss = total_loss / len(test_loader)\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_predictions)\n",
        "print('Confusion Matrix:')\n",
        "print(cm)\n",
        "\n",
        "accuracy = (cm[0, 0] + cm[1, 1]) / np.sum(cm)\n",
        "print(f'Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjd3ETylZlOx",
        "outputId": "10ebff5a-630a-47f0-b85e-6da771ac4e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[1428   53]\n",
            " [ 192   17]]\n",
            "Test Loss: 0.1083, Test Accuracy: 0.8550\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Increase the number of epochs (for example 15) will give a heigh score !!"
      ],
      "metadata": {
        "id": "XllS5OMxa_pu"
      }
    }
  ]
}